{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPS 140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "95c148d1d7f3bad1a285adcc2df86994",
     "grade": false,
     "grade_id": "cell-d2d02676a6c716dd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Assignment 1\n",
    "\n",
    "**DUE: Friday April 20, 2018 11:59pm**\n",
    "\n",
    "Turn in the assignment via Canvas.\n",
    "\n",
    "To write legible answers you will need to be familiar with both [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet) and [Latex](https://www.latex-tutorial.com/tutorials/amsmath/)\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, restart the kernel (in the menubar, select Kernel→→Restart) and then run all cells (in the menubar, select Cell→→Run All).\n",
    "\n",
    "Make sure you fill in any place that says \"YOUR CODE HERE\" or \"YOUR ANSWER HERE\", as well as your name below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Kenny Luu\"\n",
    "STUDENT_ID = \"1491158\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b0012b5d623145240cdd19dfa65be703",
     "grade": false,
     "grade_id": "cell-fbc61605f66193a2",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 1 \n",
    "\n",
    "Suppose that 13 cards are selected at random from a regular deck of 52 playing cards:\n",
    "\n",
    "a. If it is known that at least one ace has been selected, what is the probability that at least two aces have been selected?\n",
    "\n",
    "b. If it is known that the ace of hearts has been selected, what is the probability that at least two aces have been selected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a1889ce8782580117854c4f2773af870",
     "grade": true,
     "grade_id": "cell-b18eb48e93041a25",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "# Answers\n",
    "## A.\n",
    "\n",
    "Let **A** be the event of getting at least 2 Aces when 13 cards are selected:\n",
    "\n",
    "$P(A) = \\dfrac{{{4}\\choose{2}} \\cdot {{48}\\choose{11}} + {{4}\\choose{3}} \\cdot {{48}\\choose{10}} + {{4}\\choose{4}} \\cdot {{48}\\choose{9}}}{{52}\\choose{13}}$\n",
    "\n",
    "Let **B** be the event of getting at least one Ace when 13 cards are selected:\n",
    "\n",
    "$P(B) = \\dfrac{{{4}\\choose{1}} \\cdot {{48}\\choose{12}} + {{4}\\choose{2}} \\cdot {{48}\\choose{11}} + {{4}\\choose{3}} \\cdot {{48}\\choose{10}} + {{4}\\choose{4}} \\cdot {{48}\\choose{9}}}{{52}\\choose{13}}$\n",
    "\n",
    "So the probability of A given B is\n",
    "\n",
    "$P(A|B) = \\dfrac{P(A\\cap B)}{P(B)}$\n",
    "\n",
    "Since $P(A\\cap B)$ is the same as $P(A)$ we get:\n",
    "\n",
    "$P(A|B) = \\dfrac{P(A)}{P(B)}$ which is equal to: $.365$\n",
    "\n",
    "## B.\n",
    "\n",
    "Let A be the event of getting at least 2 Aces when 13 cards are selected:\n",
    "\n",
    "$P(A) = \\dfrac{{{4}\\choose{2}} \\cdot {{48}\\choose{11}} + {{4}\\choose{3}} \\cdot {{48}\\choose{10}} + {{4}\\choose{4}} \\cdot {{48}\\choose{9}}}{{52}\\choose{13}}$\n",
    "\n",
    "Let B be the event that the Ace of hearts is chosen when 13 cards are selected\n",
    "\n",
    "$P(B) = \\dfrac{{51}\\choose{12}}{{52}\\choose{13}}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "886ce8f1c285a0340b635a4b945e9ae9",
     "grade": false,
     "grade_id": "cell-63bc34a656b9f6e0",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 2\n",
    "\n",
    "\n",
    "Suppose that a person's score X on a mathematics aptitude test is a number between 0 and 1, and that a person's score on a music aptitude test is also a number between 0 and 1. Supposed further that in the population of all college students, the scores X and Y are distributed according to the following joint p.d.f.:\n",
    "\n",
    "$f(x, y) = \\frac{2}{5}(2x+3y),$ for $0 \\leq x \\leq 1$ and $0 \\leq y \\leq 1$\n",
    "\n",
    "a. What proportion of college students obtain a score greater than 0.8 on the mathematics test?\n",
    "\n",
    "b. If a student's score on the music test is 0.3, what is the probability that his/her score on the mathematics test will be greater than 0.8?\n",
    "\n",
    "c. If a student's score on the mathematics test is 0.3, what is the probability that his/her score on the music test will be greater than 0.8?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e15a7a687546c8c98d80284a2bc17582",
     "grade": true,
     "grade_id": "cell-2f061f10915044a8",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9afe5deed00addacea2ffd902cfd2a76",
     "grade": false,
     "grade_id": "cell-6c53a68749acb988",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "Write out the joint probability distribution described by the following Bayesian Network:\n",
    "\n",
    "![bayes_net](https://docs.google.com/drawings/d/e/2PACX-1vRjJ382tPK3UrxydjCmwWmMjOi-8T1wQN6hBBJhE7u3-creWY7KR-K224MPTU5IzKXtX4ILxviRUMAw/pub?w=720&h=528)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "3315e32937e66207191e55de29900077",
     "grade": true,
     "grade_id": "cell-e702292884b97e63",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "a8297d74638bd383fc868c1cbdbdc0b7",
     "grade": false,
     "grade_id": "cell-e5b71a52fa68bb04",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Problem 4\n",
    "\n",
    "Given the dataset below, use information gain to calculate the first attribute the decision tree should split on. Feel free to use the cell below to explore the dataset and facilitate with the calculations. You should show your work using LaTeX 2 cells down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data_iris, labels_iris = load_iris(return_X_y=True)\n",
    "\n",
    "print('There are {} samples with {} attributes.'.format(*data_iris.shape))\n",
    "print('The labels consist of {} classes'.format(len(np.unique(labels_iris))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4e80f0e5cf3bf5fb6848c2d982131821",
     "grade": true,
     "grade_id": "cell-9d85836f00c56d8e",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "[YOUR ANSWER HERE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5\n",
    "\n",
    "Given the dataset below, implement the logistic regression algorithm, optimizing the parameters using gradient descent and squared error as the loss function. See 18.6.4 from the textbook for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "75b88d158872f2555802d1ca4e7d57cb",
     "grade": false,
     "grade_id": "cell-3f4f2172ab68f465",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets.samples_generator import make_moons\n",
    "\n",
    "np.random.seed(33)\n",
    "data, labels = make_moons(n_samples=100, noise=0.1)\n",
    "colors = ['r' if y else 'b' for y in labels]\n",
    "print(data.shape, labels.shape)\n",
    "plt.scatter(data[:,0], data[:,1], c=colors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4a753cda013f7b7c1376e8e4d6fd26f9",
     "grade": false,
     "grade_id": "cell-14e8f247a6e4f45c",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def logistic(x, w):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def sigmoid(z):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def squared_error(y, h):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def squared_error_derivative(y, h):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def accuracy(y, h):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "def logistic_regression(x, y, loss_func, loss_func_derivative, learning_rate, num_steps=10):\n",
    "    # start with intial parameters w_i = 1\n",
    "    w = np.ones(3)\n",
    "    # include a bias term\n",
    "    x = np.pad(x, [[0,0], [1,0]], mode='constant')\n",
    "\n",
    "    print('Intial Accuracy:{}%'.format(accuracy(y, np.round(logistic(x, w)))))\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        output = logistic(x, w)\n",
    "        update = np.dot(loss_func(y, output) * loss_func_derivative(y, output), x)\n",
    "        w = w + learning_rate * update\n",
    "        print('Step {} Accuracy:{}%'.format(step+1,accuracy(y, np.round(logistic(x, w)))))\n",
    "    return w\n",
    "    \n",
    "\n",
    "ws = logistic_regression(data, labels, squared_error, squared_error_derivative, 0.5)\n",
    "yh = np.round(logistic(np.pad(data, [[0,0], [1,0]], mode='constant'), ws))\n",
    "colors = ['g' if _yh==_y else 'r' for _yh, _y in zip(yh, labels.astype(np.int))]\n",
    "plt.title('Classification Results')\n",
    "plt.scatter(data[:,0], data[:,1], c=colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "48af5556e545939d398fc0b508377e08",
     "grade": true,
     "grade_id": "cell-5c2d005f666d2961",
     "locked": true,
     "points": 0,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "correct_w = np.array([ 1.        ,  0.51003169, -1.56964452])\n",
    "np.testing.assert_allclose(logistic_regression(data, labels, squared_error, squared_error_derivative, 0.5),\n",
    "                           correct_w,\n",
    "                           rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6\n",
    "\n",
    "Implement a single perceptron below.\n",
    "\n",
    "You can assume that both **x** and **w** will be iterables and b will be a single value. All of them will not be *None*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "23ec0179033bbc5ec963ac98baf613fb",
     "grade": false,
     "grade_id": "cell-6ad288911fa0e2a9",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def perceptron(x, w, b):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f8e4fb18f036abcf7180c285e531fd24",
     "grade": true,
     "grade_id": "cell-0beeecf3cc6d7e32",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert perceptron([1, 2], [1, 1], 0) == 1\n",
    "assert perceptron([1, 2], [1, 1], -5) == 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
